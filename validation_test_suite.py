#!/usr/bin/env python3
"""–ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ò –í–ê–õ–ò–î–ê–¶–ò–ò
–ü—Ä–æ–≤–µ—Ä–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π #1-3

–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: 30 —Å–µ–Ω—Ç—è–±—Ä—è 2025
–¶–µ–ª—å: –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π (–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç, —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫)
"""

import asyncio
import json
import logging
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta

from real_data_reports import RealDataFinancialReports

import api_clients_main as api_clients
from api_chunking import ChunkedAPIManager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(
            f'/root/sovani_bot/validation_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        ),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


@dataclass
class TestResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞"""

    test_name: str
    period_start: str
    period_end: str
    period_days: int

    # –î–∞–Ω–Ω—ã–µ –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    raw_records_count: int

    # –î–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
    unique_records_count: int
    duplicates_removed: int
    deduplication_percent: float

    # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    net_revenue_to_seller: float  # forPay
    gross_sales_value: float  # priceWithDisc
    wb_total_deductions: float
    units_sold: int

    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    records_outside_period: int
    date_parsing_errors: int

    # –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    expected_revenue: float | None = None

    # –¢–æ—á–Ω–æ—Å—Ç—å
    accuracy_percent: float | None = None

    # –°—Ç–∞—Ç—É—Å —Ç–µ—Å—Ç–∞
    test_passed: bool = False
    notes: str = ""


@dataclass
class ValidationReport:
    """–ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""

    report_date: str
    tests_total: int
    tests_passed: int
    tests_failed: int

    overall_accuracy: float
    deduplication_effectiveness: float
    date_filtering_quality: float

    test_results: list[TestResult]

    recommendations: list[str]
    summary: str


class ValidationTestSuite:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π"""

    def __init__(self):
        self.reports = RealDataFinancialReports()
        self.chunked_api = ChunkedAPIManager(api_clients)

        # –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ì–û –ê–£–î–ò–¢–ê
        self.reference_data = {
            "january_2025": {
                "date_from": "2025-01-01",
                "date_to": "2025-01-31",
                "expected_orders_value": 113595,  # –ò–∑ –∞—É–¥–∏—Ç–∞
                "expected_sales_value": 60688,  # –ò–∑ –∞—É–¥–∏—Ç–∞
                "description": "–Ø–Ω–≤–∞—Ä—å 2025 - —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏",
            }
        }

    async def test_1_day_period(self) -> TestResult:
        """–¢–ï–°–¢ 1: –ü–µ—Ä–∏–æ–¥ 1 –¥–µ–Ω—å
        –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –±–µ–∑ —á–∞–Ω–∫–∏–Ω–≥–∞
        """
        logger.info("=" * 80)
        logger.info("üß™ –¢–ï–°–¢ 1: –ü–ï–†–ò–û–î 1 –î–ï–ù–¨")
        logger.info("=" * 80)

        date_to = datetime.now().strftime("%Y-%m-%d")
        date_from = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")

        return await self._run_test(
            test_name="–¢–µ—Å—Ç 1: –ü–µ—Ä–∏–æ–¥ 1 –¥–µ–Ω—å",
            date_from=date_from,
            date_to=date_to,
            expected_revenue=None,  # –ù–µ—Ç —ç—Ç–∞–ª–æ–Ω–∞
        )

    async def test_7_days_period(self) -> TestResult:
        """–¢–ï–°–¢ 2: –ü–µ—Ä–∏–æ–¥ 7 –¥–Ω–µ–π
        –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞ 1-2 —á–∞–Ω–∫–∞—Ö
        """
        logger.info("=" * 80)
        logger.info("üß™ –¢–ï–°–¢ 2: –ü–ï–†–ò–û–î 7 –î–ù–ï–ô")
        logger.info("=" * 80)

        date_to = datetime.now().strftime("%Y-%m-%d")
        date_from = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")

        return await self._run_test(
            test_name="–¢–µ—Å—Ç 2: –ü–µ—Ä–∏–æ–¥ 7 –¥–Ω–µ–π",
            date_from=date_from,
            date_to=date_to,
            expected_revenue=None,
        )

    async def test_30_days_period(self) -> TestResult:
        """–¢–ï–°–¢ 3: –ü–µ—Ä–∏–æ–¥ 30 –¥–Ω–µ–π (1 –º–µ—Å—è—Ü)
        –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –Ω–∞ 1-2 —á–∞–Ω–∫–∞—Ö
        """
        logger.info("=" * 80)
        logger.info("üß™ –¢–ï–°–¢ 3: –ü–ï–†–ò–û–î 30 –î–ù–ï–ô")
        logger.info("=" * 80)

        date_to = datetime.now().strftime("%Y-%m-%d")
        date_from = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

        return await self._run_test(
            test_name="–¢–µ—Å—Ç 3: –ü–µ—Ä–∏–æ–¥ 30 –¥–Ω–µ–π",
            date_from=date_from,
            date_to=date_to,
            expected_revenue=None,
        )

    async def test_january_2025_reference(self) -> TestResult:
        """–¢–ï–°–¢ 4: –Ø–Ω–≤–∞—Ä—å 2025 (–≠–¢–ê–õ–û–ù–ù–´–ô)
        –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞—É–¥–∏—Ç–∞
        –û–∂–∏–¥–∞–µ—Ç—Å—è: ~113,595‚ÇΩ –∑–∞–∫–∞–∑—ã, ~60,688‚ÇΩ –≤—ã–∫—É–ø—ã
        """
        logger.info("=" * 80)
        logger.info("üß™ –¢–ï–°–¢ 4: –Ø–ù–í–ê–†–¨ 2025 (–≠–¢–ê–õ–û–ù–ù–´–ô)")
        logger.info("=" * 80)

        ref = self.reference_data["january_2025"]

        logger.info("üìã –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        logger.info(f"   –û–∂–∏–¥–∞–µ–º—ã–µ –∑–∞–∫–∞–∑—ã: {ref['expected_orders_value']:,.0f} ‚ÇΩ")
        logger.info(f"   –û–∂–∏–¥–∞–µ–º—ã–µ –≤—ã–∫—É–ø—ã: {ref['expected_sales_value']:,.0f} ‚ÇΩ")

        return await self._run_test(
            test_name="–¢–µ—Å—Ç 4: –Ø–Ω–≤–∞—Ä—å 2025 (—ç—Ç–∞–ª–æ–Ω–Ω—ã–π)",
            date_from=ref["date_from"],
            date_to=ref["date_to"],
            expected_revenue=ref["expected_sales_value"],
        )

    async def _run_test(
        self, test_name: str, date_from: str, date_to: str, expected_revenue: float | None = None
    ) -> TestResult:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞

        –≠—Ç–∞–ø—ã:
        1. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å –ø–æ–¥—Å—á–µ—Ç–æ–º)
        2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞—Ç
        4. –†–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
        5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º (–µ—Å–ª–∏ –µ—Å—Ç—å)
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"üî¨ {test_name}")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {date_from} - {date_to}")
        logger.info(f"{'='*80}\n")

        period_days = (
            datetime.strptime(date_to, "%Y-%m-%d") - datetime.strptime(date_from, "%Y-%m-%d")
        ).days + 1

        try:
            # –®–ê–ì 1: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            logger.info("üì• –®–ê–ì 1: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö WB Sales...")

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π API
            raw_sales = await self.chunked_api.get_wb_sales_chunked(date_from, date_to)
            raw_records_count = len(raw_sales) if raw_sales else 0

            logger.info(f"   –ü–æ–ª—É—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {raw_records_count}")

            # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (—É–∂–µ –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ ChunkedAPIManager)
            logger.info("\nüîç –®–ê–ì 2: –ê–Ω–∞–ª–∏–∑ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏...")

            # –ü–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö saleID
            unique_sale_ids = set()
            duplicates_in_raw = 0

            for sale in raw_sales:
                sale_id = sale.get("saleID")
                if sale_id:
                    if sale_id in unique_sale_ids:
                        duplicates_in_raw += 1
                    else:
                        unique_sale_ids.add(sale_id)

            unique_records_count = len(unique_sale_ids)
            duplicates_removed = duplicates_in_raw
            deduplication_percent = (
                (duplicates_removed / raw_records_count * 100) if raw_records_count > 0 else 0
            )

            logger.info(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö saleID: {unique_records_count}")
            logger.info(
                f"   –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {duplicates_removed} ({deduplication_percent:.1f}%)"
            )

            if duplicates_removed == 0:
                logger.info("   ‚úÖ –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç!")
            else:
                logger.warning(f"   ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏–∫—É!")

            # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞—Ç
            logger.info("\nüìÖ –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞—Ç...")

            records_outside_period = 0
            date_parsing_errors = 0

            from real_data_reports import is_date_in_range

            for sale in raw_sales:
                record_date = sale.get("date", "")
                if not record_date:
                    date_parsing_errors += 1
                    continue

                try:
                    if not is_date_in_range(record_date, date_from, date_to):
                        records_outside_period += 1
                except Exception:
                    date_parsing_errors += 1

            logger.info(f"   –ó–∞–ø–∏—Å–µ–π –≤–Ω–µ –ø–µ—Ä–∏–æ–¥–∞: {records_outside_period}")
            logger.info(f"   –û—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç: {date_parsing_errors}")

            if records_outside_period == 0 and date_parsing_errors == 0:
                logger.info("   ‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
            else:
                logger.warning("   ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –¥–∞—Ç")

            # –®–ê–ì 4: –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É –æ—Ç—á–µ—Ç–æ–≤
            logger.info("\nüí∞ –®–ê–ì 4: –†–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫...")

            result = await self.reports.get_real_wb_data(date_from, date_to)

            net_revenue_to_seller = result.get("revenue", 0)
            gross_sales_value = result.get("gross_sales_value", 0)
            wb_total_deductions = result.get("wb_total_deductions", 0)
            units_sold = result.get("units", 0)

            logger.info(f"   üíµ –ß–∏—Å—Ç–∞—è –≤—ã—Ä—É—á–∫–∞ (forPay): {net_revenue_to_seller:,.2f} ‚ÇΩ")
            logger.info(f"   üí∞ –í–∞–ª–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å (priceWithDisc): {gross_sales_value:,.2f} ‚ÇΩ")
            logger.info(f"   üìâ –£–¥–µ—Ä–∂–∞–Ω–∏—è WB: {wb_total_deductions:,.2f} ‚ÇΩ")
            logger.info(f"   üì¶ –ï–¥–∏–Ω–∏—Ü –ø—Ä–æ–¥–∞–Ω–æ: {units_sold}")

            # –®–ê–ì 5: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º
            accuracy_percent = None
            test_passed = False
            notes = []

            if expected_revenue is not None:
                logger.info("\nüéØ –®–ê–ì 5: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")

                deviation = abs(net_revenue_to_seller - expected_revenue)
                accuracy_percent = (
                    100 - (deviation / expected_revenue * 100) if expected_revenue > 0 else 0
                )

                logger.info(f"   –û–∂–∏–¥–∞–µ–º–∞—è –≤—ã—Ä—É—á–∫–∞: {expected_revenue:,.2f} ‚ÇΩ")
                logger.info(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –≤—ã—Ä—É—á–∫–∞: {net_revenue_to_seller:,.2f} ‚ÇΩ")
                logger.info(f"   –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation:,.2f} ‚ÇΩ ({100 - accuracy_percent:.1f}%)")
                logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_percent:.1f}%")

                # –ö—Ä–∏—Ç–µ—Ä–∏–π —É—Å–ø–µ—Ö–∞: —Ç–æ—á–Ω–æ—Å—Ç—å >= 95%
                if accuracy_percent >= 95.0:
                    test_passed = True
                    logger.info("   ‚úÖ –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù: –¢–æ—á–Ω–æ—Å—Ç—å >= 95%")
                else:
                    logger.warning(f"   ‚ùå –¢–ï–°–¢ –ù–ï –ü–†–û–ô–î–ï–ù: –¢–æ—á–Ω–æ—Å—Ç—å {accuracy_percent:.1f}% < 95%")
                    notes.append(f"–¢–æ—á–Ω–æ—Å—Ç—å {accuracy_percent:.1f}% –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ 95%")
            else:
                logger.info("\nüìä –®–ê–ì 5: –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                logger.info("   –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–ª—å–∫–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

                # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
                if duplicates_removed == 0 and records_outside_period == 0:
                    test_passed = True
                    logger.info("   ‚úÖ –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞—é—Ç")
                else:
                    logger.warning("   ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö")
                    if duplicates_removed > 0:
                        notes.append(f"–ù–∞–π–¥–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                    if records_outside_period > 0:
                        notes.append(f"{records_outside_period} –∑–∞–ø–∏—Å–µ–π –≤–Ω–µ –ø–µ—Ä–∏–æ–¥–∞")

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞
            test_result = TestResult(
                test_name=test_name,
                period_start=date_from,
                period_end=date_to,
                period_days=period_days,
                raw_records_count=raw_records_count,
                unique_records_count=unique_records_count,
                duplicates_removed=duplicates_removed,
                deduplication_percent=deduplication_percent,
                net_revenue_to_seller=net_revenue_to_seller,
                gross_sales_value=gross_sales_value,
                wb_total_deductions=wb_total_deductions,
                units_sold=units_sold,
                records_outside_period=records_outside_period,
                date_parsing_errors=date_parsing_errors,
                expected_revenue=expected_revenue,
                accuracy_percent=accuracy_percent,
                test_passed=test_passed,
                notes="; ".join(notes) if notes else "OK",
            )

            logger.info(f"\n{'='*80}")
            logger.info(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –¢–ï–°–¢–ê: {'‚úÖ –ü–†–û–ô–î–ï–ù' if test_passed else '‚ùå –ù–ï –ü–†–û–ô–î–ï–ù'}")
            logger.info(f"{'='*80}\n")

            return test_result

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ç–µ—Å—Ç–∞: {e}", exc_info=True)

            return TestResult(
                test_name=test_name,
                period_start=date_from,
                period_end=date_to,
                period_days=period_days,
                raw_records_count=0,
                unique_records_count=0,
                duplicates_removed=0,
                deduplication_percent=0,
                net_revenue_to_seller=0,
                gross_sales_value=0,
                wb_total_deductions=0,
                units_sold=0,
                records_outside_period=0,
                date_parsing_errors=0,
                test_passed=False,
                notes=f"–û—à–∏–±–∫–∞: {e!s}",
            )

    async def run_all_tests(self) -> ValidationReport:
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        logger.info("\n" + "=" * 80)
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ù–ê–ë–û–†–ê –¢–ï–°–¢–û–í")
        logger.info("=" * 80)
        logger.info(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("–¶–µ–ª—å: –í–∞–ª–∏–¥–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π #1-3")
        logger.info("=" * 80 + "\n")

        test_results = []

        # –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
        test_results.append(await self.test_1_day_period())
        test_results.append(await self.test_7_days_period())
        test_results.append(await self.test_30_days_period())
        test_results.append(await self.test_january_2025_reference())

        # –ü–æ–¥—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤
        tests_total = len(test_results)
        tests_passed = sum(1 for t in test_results if t.test_passed)
        tests_failed = tests_total - tests_passed

        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        total_duplicates = sum(t.duplicates_removed for t in test_results)
        total_records = sum(t.raw_records_count for t in test_results)
        deduplication_effectiveness = (
            (total_duplicates / total_records * 100) if total_records > 0 else 0
        )

        total_outside_period = sum(t.records_outside_period for t in test_results)
        date_filtering_quality = (
            100 - (total_outside_period / total_records * 100) if total_records > 0 else 100
        )

        # –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤ —Å —ç—Ç–∞–ª–æ–Ω–æ–º)
        accuracy_tests = [t for t in test_results if t.accuracy_percent is not None]
        overall_accuracy = (
            sum(t.accuracy_percent for t in accuracy_tests) / len(accuracy_tests)
            if accuracy_tests
            else 0
        )

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = []

        if deduplication_effectiveness > 5:
            recommendations.append(
                f"‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ({deduplication_effectiveness:.1f}%). "
                "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏–∫—É chunking."
            )
        elif deduplication_effectiveness == 0:
            recommendations.append("‚úÖ –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ!")

        if date_filtering_quality < 99:
            recommendations.append(
                f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –∑–∞–ø–∏—Å–∏ –≤–Ω–µ –ø–µ—Ä–∏–æ–¥–∞ ({100 - date_filtering_quality:.1f}%). "
                "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–ª—É—á—à–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –¥–∞—Ç."
            )
        else:
            recommendations.append("‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")

        if overall_accuracy >= 95:
            recommendations.append(
                f"‚úÖ –¶–µ–ª–µ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞: {overall_accuracy:.1f}% >= 95%"
            )
        elif overall_accuracy > 0:
            recommendations.append(
                f"‚ö†Ô∏è –¢–æ—á–Ω–æ—Å—Ç—å {overall_accuracy:.1f}% –Ω–∏–∂–µ —Ü–µ–ª–µ–≤–æ–π 95%. "
                "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞."
            )

        # –ò—Ç–æ–≥–æ–≤—ã–π summary
        summary = f"""
–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –û –í–ê–õ–ò–î–ê–¶–ò–ò:

–¢–µ—Å—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {tests_total}
–¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ: {tests_passed} ({tests_passed/tests_total*100:.0f}%)
–¢–µ—Å—Ç–æ–≤ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–æ: {tests_failed}

–≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô:
- –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: {100 - deduplication_effectiveness:.1f}% (—É–¥–∞–ª–µ–Ω–æ {deduplication_effectiveness:.1f}% –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç: {date_filtering_quality:.1f}%
- –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {overall_accuracy:.1f}%

–°–¢–ê–¢–£–°: {'‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´' if tests_failed == 0 else '‚ö†Ô∏è –ï–°–¢–¨ –ü–†–û–ë–õ–ï–ú–´'}
"""

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report = ValidationReport(
            report_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            tests_total=tests_total,
            tests_passed=tests_passed,
            tests_failed=tests_failed,
            overall_accuracy=overall_accuracy,
            deduplication_effectiveness=100 - deduplication_effectiveness,
            date_filtering_quality=date_filtering_quality,
            test_results=test_results,
            recommendations=recommendations,
            summary=summary,
        )

        # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        logger.info("\n" + "=" * 80)
        logger.info("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –û –í–ê–õ–ò–î–ê–¶–ò–ò")
        logger.info("=" * 80)
        logger.info(summary)

        logger.info("\nüìã –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        for i, rec in enumerate(recommendations, 1):
            logger.info(f"{i}. {rec}")

        logger.info("\n" + "=" * 80)

        return report

    def save_report(self, report: ValidationReport, filepath: str = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ JSON"""
        if filepath is None:
            filepath = f'/root/sovani_bot/validation_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ dict
        report_dict = asdict(report)

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(report_dict, f, ensure_ascii=False, indent=2)

        logger.info(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")

        return filepath


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    suite = ValidationTestSuite()

    # –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
    report = await suite.run_all_tests()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_path = suite.save_report(report)

    logger.info("\n‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    logger.info(f"üìä –û—Ç—á–µ—Ç: {report_path}")

    return report


if __name__ == "__main__":
    report = asyncio.run(main())
