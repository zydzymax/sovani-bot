"""‚ö° –ú–û–î–£–õ–¨ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò

–í–∫–ª—é—á–∞–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø—É–ª–∏–Ω–≥ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
–¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.
"""

import hashlib
import json
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """–ó–∞–ø–∏—Å—å –≤ –∫—ç—à–µ —Å –≤—Ä–µ–º–µ–Ω–µ–º –∏—Å—Ç–µ—á–µ–Ω–∏—è"""

    data: Any
    created_at: datetime
    expires_at: datetime
    access_count: int = 0
    last_access: datetime | None = None


class PerformanceOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""

    def __init__(self, default_ttl_minutes: int = 30):
        self.cache: dict[str, CacheEntry] = {}
        self.default_ttl = timedelta(minutes=default_ttl_minutes)
        self.cache_stats = {"hits": 0, "misses": 0, "evictions": 0}
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–∫–∏ –ø–∞–º—è—Ç–∏
        self.max_cache_size = 1000

    def _generate_cache_key(self, prefix: str, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º kwargs –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–ª—é—á–µ–π
        sorted_kwargs = sorted(kwargs.items())
        content = f"{prefix}:{json.dumps(sorted_kwargs, sort_keys=True)}"
        return hashlib.md5(content.encode()).hexdigest()

    def _cleanup_expired(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç—ë–∫—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –∫—ç—à–∞"""
        now = datetime.now()
        expired_keys = [key for key, entry in self.cache.items() if entry.expires_at < now]

        for key in expired_keys:
            del self.cache[key]
            self.cache_stats["evictions"] += 1

        # –ï—Å–ª–∏ –∫—ç—à —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —É–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
        if len(self.cache) > self.max_cache_size:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            sorted_entries = sorted(
                self.cache.items(), key=lambda x: x[1].last_access or x[1].created_at
            )

            # –£–¥–∞–ª—è–µ–º 20% —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
            to_remove = len(self.cache) // 5
            for key, _ in sorted_entries[:to_remove]:
                del self.cache[key]
                self.cache_stats["evictions"] += 1

    def get_cached(self, cache_key: str) -> Any | None:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫—ç—à–∞"""
        self._cleanup_expired()

        if cache_key in self.cache:
            entry = self.cache[cache_key]
            entry.access_count += 1
            entry.last_access = datetime.now()
            self.cache_stats["hits"] += 1
            logger.debug(f"üìã Cache HIT: {cache_key[:8]}...")
            return entry.data

        self.cache_stats["misses"] += 1
        logger.debug(f"üíî Cache MISS: {cache_key[:8]}...")
        return None

    def set_cached(self, cache_key: str, data: Any, ttl_minutes: int | None = None) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à"""
        ttl = timedelta(minutes=ttl_minutes) if ttl_minutes else self.default_ttl
        now = datetime.now()

        entry = CacheEntry(
            data=data, created_at=now, expires_at=now + ttl, access_count=1, last_access=now
        )

        self.cache[cache_key] = entry
        logger.debug(f"üíæ Cache SET: {cache_key[:8]}... (TTL: {ttl_minutes or 30}m)")

    def cache_api_response(self, api_name: str, method: str, **params):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ API"""

        def decorator(func):
            async def wrapper(*args, **kwargs):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á –∫—ç—à–∞
                cache_key = self._generate_cache_key(f"{api_name}:{method}", **params, **kwargs)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
                cached_result = self.get_cached(cache_key)
                if cached_result is not None:
                    return cached_result

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
                result = await func(*args, **kwargs)

                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (API –¥–∞–Ω–Ω—ã–µ –∫—ç—à–∏—Ä—É–µ–º –Ω–∞ 15 –º–∏–Ω—É—Ç)
                self.set_cached(cache_key, result, ttl_minutes=15)

                return result

            return wrapper

        return decorator

    def get_cache_stats(self) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞"""
        total_requests = self.cache_stats["hits"] + self.cache_stats["misses"]
        hit_rate = (self.cache_stats["hits"] / total_requests * 100) if total_requests > 0 else 0

        return {
            "cache_size": len(self.cache),
            "total_requests": total_requests,
            "hit_rate_percent": round(hit_rate, 2),
            "hits": self.cache_stats["hits"],
            "misses": self.cache_stats["misses"],
            "evictions": self.cache_stats["evictions"],
        }

    def clear_cache(self, pattern: str | None = None) -> int:
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ (–ø–æ–ª–Ω–∞—è –∏–ª–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É)"""
        if pattern is None:
            cleared = len(self.cache)
            self.cache.clear()
            logger.info(f"üßπ –û—á–∏—â–µ–Ω –≤–µ—Å—å –∫—ç—à: {cleared} –∑–∞–ø–∏—Å–µ–π")
            return cleared

        # –û—á–∏—Å—Ç–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É (–ø—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—é –ø–æ–¥—Å—Ç—Ä–æ–∫–∏)
        keys_to_remove = [key for key in self.cache.keys() if pattern in key]
        for key in keys_to_remove:
            del self.cache[key]

        logger.info(f"üßπ –û—á–∏—â–µ–Ω –∫—ç—à –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É '{pattern}': {len(keys_to_remove)} –∑–∞–ø–∏—Å–µ–π")
        return len(keys_to_remove)


class DataProcessor:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–∞–Ω–Ω—ã—Ö"""

    @staticmethod
    def batch_process_sales(
        sales_data: list[dict[str, Any]], batch_size: int = 1000
    ) -> dict[str, Any]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if not sales_data:
            return {"total_revenue": 0, "total_items": 0, "processed_batches": 0}

        total_revenue = 0
        total_items = 0
        processed_batches = 0

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        for i in range(0, len(sales_data), batch_size):
            batch = sales_data[i : i + batch_size]

            # –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞
            batch_revenue = sum(
                sale.get("forPay", 0)
                for sale in batch
                if isinstance(sale.get("forPay"), (int, float))
            )

            total_revenue += batch_revenue
            total_items += len(batch)
            processed_batches += 1

        logger.debug(f"‚ö° –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_items} –ø—Ä–æ–¥–∞–∂ –∑–∞ {processed_batches} –±–∞—Ç—á–µ–π")

        return {
            "total_revenue": total_revenue,
            "total_items": total_items,
            "processed_batches": processed_batches,
        }

    @staticmethod
    def optimize_date_filtering(
        data: list[dict[str, Any]], date_field: str, date_from: str, date_to: str
    ) -> list[dict[str, Any]]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º"""
        if not data:
            return []

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç –≤ –ø–µ—Ä–≤—ã—Ö –∑–∞–ø–∏—Å—è—Ö
        sample_size = min(10, len(data))
        date_formats = set()

        for item in data[:sample_size]:
            if item.get(date_field):
                date_str = item[date_field]
                if "T" in date_str:
                    date_formats.add("iso_with_time")
                elif "." in date_str:
                    date_formats.add("dot_format")
                else:
                    date_formats.add("iso_date")

        # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        if "iso_with_time" in date_formats:
            return [
                item
                for item in data
                if date_field in item
                and item[date_field]
                and date_from <= item[date_field].split("T")[0] <= date_to
            ]
        else:
            return [
                item
                for item in data
                if date_field in item
                and item[date_field]
                and date_from <= item[date_field][:10] <= date_to
            ]


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
performance_optimizer = PerformanceOptimizer()


def get_performance_stats() -> dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    cache_stats = performance_optimizer.get_cache_stats()

    return {
        "cache_stats": cache_stats,
        "optimizer_status": "active",
        "recommendations": _generate_performance_recommendations(cache_stats),
    }


def _generate_performance_recommendations(cache_stats: dict[str, Any]) -> list[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    recommendations = []

    hit_rate = cache_stats.get("hit_rate_percent", 0)

    if hit_rate < 30:
        recommendations.append("üìà –ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ TTL")
    elif hit_rate > 80:
        recommendations.append("üéØ –û—Ç–ª–∏—á–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è!")

    cache_size = cache_stats.get("cache_size", 0)
    if cache_size > 800:
        recommendations.append("üßπ –ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—á–∏—Å—Ç–∫–∞")

    evictions = cache_stats.get("evictions", 0)
    if evictions > 100:
        recommendations.append("‚ôªÔ∏è –ú–Ω–æ–≥–æ –≤—ã—Ç–µ—Å–Ω–µ–Ω–∏–π –∏–∑ –∫—ç—à–∞. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫—ç—à–∞")

    return recommendations or ["‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –Ω–æ—Ä–º–µ"]


def optimize_chunking_strategy(
    total_days: int, api_type: str, target_chunks: int = 10
) -> tuple[int, int]:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ —á–∞–Ω–∫–∏

    Args:
        total_days: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        api_type: –¢–∏–ø API (wb_sales, ozon_fbo –∏ —Ç.–¥.)
        target_chunks: –ñ–µ–ª–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤

    Returns:
        Tuple[int, int]: (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π_—Ä–∞–∑–º–µ—Ä_—á–∞–Ω–∫–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—á–∞–Ω–∫–æ–≤)

    """
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö API
    max_chunk_sizes = {
        "wb_sales": 28,
        "wb_orders": 28,
        "wb_advertising": 14,
        "ozon_fbo": 30,
        "ozon_fbs": 30,
    }

    max_chunk = max_chunk_sizes.get(api_type, 30)

    # –ï—Å–ª–∏ –æ–±—â–∏–π –ø–µ—Ä–∏–æ–¥ –º–µ–Ω—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∞–Ω–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω —á–∞–Ω–∫
    if total_days <= max_chunk:
        return total_days, 1

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
    optimal_chunk_size = min(max_chunk, max(1, total_days // target_chunks))
    actual_chunks = (total_days + optimal_chunk_size - 1) // optimal_chunk_size

    logger.debug(
        f"‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–∞–Ω–∫–∏–Ω–≥–∞ {api_type}: {total_days} –¥–Ω–µ–π ‚Üí {actual_chunks} —á–∞–Ω–∫–æ–≤ –ø–æ {optimal_chunk_size} –¥–Ω–µ–π"
    )

    return optimal_chunk_size, actual_chunks
