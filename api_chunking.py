"""–°–∏—Å—Ç–µ–º–∞ —Ä–∞–∑–±–∏–≤–∫–∏ –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–∞—Ç –Ω–∞ –º–µ–Ω—å—à–∏–µ –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Any

logger = logging.getLogger(__name__)


class APIChunker:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–∞—Ç –Ω–∞ –º–µ–Ω—å—à–∏–µ —á–∞–Ω–∫–∏ –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤"""

    # –ö–†–ò–¢–ò–ß–ù–û –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ô –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
    MAX_PERIODS = {
        "wb_sales": 45,  # –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤
        "wb_orders": 45,  # –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –º–µ–Ω—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞–Ω–∫–æ–≤
        "wb_advertising": 21,  # –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 14 –¥–æ 21 –¥–Ω—è (–Ω–æ –≤—Å–µ –µ—â–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ)
        "ozon_fbo": 60,  # –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 60 –¥–Ω–µ–π (Ozon –≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–æ–ª—å—à–µ)
        "ozon_fbs": 60,  # –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 60 –¥–Ω–µ–π (Ozon –≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–æ–ª—å—à–µ)
        "ozon_advertising": 60,  # –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 60 –¥–Ω–µ–π (Ozon –≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–æ–ª—å—à–µ)
    }

    @staticmethod
    def parse_date(date_str: str) -> datetime:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ –¥–∞—Ç—ã –≤ –æ–±—ä–µ–∫—Ç datetime"""
        return datetime.strptime(date_str, "%Y-%m-%d")

    @staticmethod
    def format_date(date_obj: datetime) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ datetime –≤ —Å—Ç—Ä–æ–∫—É"""
        return date_obj.strftime("%Y-%m-%d")

    @classmethod
    def chunk_date_range(cls, date_from: str, date_to: str, api_type: str) -> list[tuple[str, str]]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –ø–µ—Ä–∏–æ–¥ –¥–∞—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º API

        Args:
            date_from: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
            date_to: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
            api_type: –¢–∏–ø API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (date_from, date_to) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞

        """
        start_date = cls.parse_date(date_from)
        end_date = cls.parse_date(date_to)

        max_days = cls.MAX_PERIODS.get(api_type, 30)
        chunks = []

        current_start = start_date

        while current_start <= end_date:
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
            current_end = min(current_start + timedelta(days=max_days - 1), end_date)

            chunks.append((cls.format_date(current_start), cls.format_date(current_end)))

            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —á–∞–Ω–∫—É
            current_start = current_end + timedelta(days=1)

        logger.info(
            f"–†–∞–∑–±–∏–ª–∏ –ø–µ—Ä–∏–æ–¥ {date_from} - {date_to} –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è API {api_type}"
        )
        return chunks

    @staticmethod
    async def process_chunked_request(
        api_func,
        date_from: str,
        date_to: str,
        api_type: str,
        delay_between_requests: float = 0.5,
        **kwargs,
    ) -> list[Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç API –∑–∞–ø—Ä–æ—Å—ã –ø–æ —á–∞–Ω–∫–∞–º –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

        Args:
            api_func: –§—É–Ω–∫—Ü–∏—è API –¥–ª—è –≤—ã–∑–æ–≤–∞
            date_from: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
            date_to: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
            api_type: –¢–∏–ø API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–æ–≤
            delay_between_requests: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API —Ñ—É–Ω–∫—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤

        """
        chunks = APIChunker.chunk_date_range(date_from, date_to, api_type)
        results = []

        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è {api_type}")

        for i, (chunk_from, chunk_to) in enumerate(chunks, 1):
            try:
                logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫ {i}/{len(chunks)}: {chunk_from} - {chunk_to}")

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
                result = await api_func(chunk_from, chunk_to, **kwargs)
                results.append(result)

                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limiting
                if i < len(chunks):
                    await asyncio.sleep(delay_between_requests)

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ {chunk_from} - {chunk_to}: {e}")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
                results.append(None)

        logger.info(f"–ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤ –¥–ª—è {api_type}")
        return results

    @staticmethod
    def aggregate_wb_sales_data(chunked_results: list[Any]) -> list[dict]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ WB Sales API —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π

        –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï (30.09.2025):
        –î–æ–±–∞–≤–ª–µ–Ω–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ saleID –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–≥–æ —É—á–µ—Ç–∞
        –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ –ø—Ä–æ–¥–∞–∂ –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —á–∞–Ω–∫–æ–≤.

        –ü–†–û–ë–õ–ï–ú–ê: API –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –æ–¥–Ω—É –ø—Ä–æ–¥–∞–∂—É –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞–Ω–∫–∞—Ö,
        —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–ª–æ –∫ –∑–∞–≤—ã—à–µ–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö –≤ 5-10 —Ä–∞–∑.
        """
        seen_sale_ids = set()
        unique_sales = []
        total_records = 0
        duplicates_removed = 0

        for result in chunked_results:
            if result and isinstance(result, list):
                total_records += len(result)
                for sale in result:
                    sale_id = sale.get("saleID")

                    if sale_id:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∏–¥–µ–ª–∏ –ª–∏ –º—ã —ç—Ç—É –ø—Ä–æ–¥–∞–∂—É —Ä–∞–Ω—å—à–µ
                        if sale_id not in seen_sale_ids:
                            seen_sale_ids.add(sale_id)
                            unique_sales.append(sale)
                        else:
                            duplicates_removed += 1
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç saleID, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å (–Ω–æ —ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)
                        unique_sales.append(sale)
                        logger.warning(f"‚ö†Ô∏è WB Sale –±–µ–∑ saleID: {sale}")

        if duplicates_removed > 0:
            logger.warning(
                f"üîç –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è WB Sales: {total_records} –∑–∞–ø–∏—Å–µ–π ‚Üí "
                f"{len(unique_sales)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö (—É–¥–∞–ª–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, "
                f"{duplicates_removed/total_records*100:.1f}%)"
            )
        else:
            logger.info(
                f"‚úÖ WB Sales: {len(unique_sales)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            )

        return unique_sales

    @staticmethod
    def aggregate_wb_orders_data(chunked_results: list[Any]) -> list[dict]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ WB Orders API —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π

        –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï (30.09.2025):
        –î–æ–±–∞–≤–ª–µ–Ω–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ —Å–æ—Å—Ç–∞–≤–Ω–æ–º—É –∫–ª—é—á—É –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è
        –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–≥–æ —É—á–µ—Ç–∞ –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ –∑–∞–∫–∞–∑–æ–≤.

        –ü–†–û–ë–õ–ï–ú–ê: Orders API –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –æ–¥–∏–Ω –∑–∞–∫–∞–∑ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞–Ω–∫–∞—Ö.
        –£ Orders –Ω–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á:
        date + nmId + odid + priceWithDisc
        """
        seen_order_keys = set()
        unique_orders = []
        total_records = 0
        duplicates_removed = 0

        for result in chunked_results:
            if result and isinstance(result, list):
                total_records += len(result)
                for order in result:
                    # –°–æ–∑–¥–∞–µ–º —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                    order_date = order.get("date", "")
                    nm_id = order.get("nmId", "")
                    od_id = order.get("odid", "")
                    price = order.get("priceWithDisc", 0)

                    # –§–æ—Ä–º–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
                    order_key = f"{order_date}_{nm_id}_{od_id}_{price}"

                    if order_key not in seen_order_keys:
                        seen_order_keys.add(order_key)
                        unique_orders.append(order)
                    else:
                        duplicates_removed += 1

        if duplicates_removed > 0:
            logger.warning(
                f"üîç –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è WB Orders: {total_records} –∑–∞–ø–∏—Å–µ–π ‚Üí "
                f"{len(unique_orders)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö (—É–¥–∞–ª–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, "
                f"{duplicates_removed/total_records*100:.1f}%)"
            )
        else:
            logger.info(
                f"‚úÖ WB Orders: {len(unique_orders)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            )

        return unique_orders

    @staticmethod
    def aggregate_wb_advertising_data(chunked_results: list[Any]) -> dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ WB Advertising API"""
        total_spend = 0.0
        total_views = 0
        total_clicks = 0
        campaigns = []

        for result in chunked_results:
            if result and isinstance(result, dict):
                total_spend += result.get("total_spend", 0.0)
                total_views += result.get("total_views", 0)
                total_clicks += result.get("total_clicks", 0)
                if "campaigns" in result:
                    campaigns.extend(result["campaigns"])

        return {
            "total_spend": total_spend,
            "total_views": total_views,
            "total_clicks": total_clicks,
            "campaigns": campaigns,
        }

    @staticmethod
    def aggregate_ozon_data(chunked_results: list[Any]) -> list[dict]:
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Ozon API —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π

        –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï (30.09.2025):
        –î–æ–±–∞–≤–ª–µ–Ω–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ posting_number (–Ω–æ–º–µ—Ä –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è) –∏–ª–∏
        —Å–æ—Å—Ç–∞–≤–Ω–æ–º—É –∫–ª—é—á—É –¥–ª—è FBO/FBS —Å—Ö–µ–º.
        """
        seen_posting_numbers = set()
        unique_data = []
        total_records = 0
        duplicates_removed = 0

        for result in chunked_results:
            records = []

            if result and isinstance(result, list):
                records = result
            elif result and isinstance(result, dict) and "result" in result:
                # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ Ozon API –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ø–æ–ª–µ "result"
                if isinstance(result["result"], list):
                    records = result["result"]

            total_records += len(records)

            for record in records:
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å posting_number –∫–∞–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                posting_number = record.get("posting_number") or record.get("postingNumber")

                if posting_number:
                    if posting_number not in seen_posting_numbers:
                        seen_posting_numbers.add(posting_number)
                        unique_data.append(record)
                    else:
                        duplicates_removed += 1
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç posting_number, —Å–æ–∑–¥–∞–µ–º —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á
                    order_id = record.get("order_id", "")
                    order_number = record.get("order_number", "")
                    created_at = record.get("created_at", "")

                    composite_key = f"{order_id}_{order_number}_{created_at}"

                    if composite_key not in seen_posting_numbers:
                        seen_posting_numbers.add(composite_key)
                        unique_data.append(record)
                    else:
                        duplicates_removed += 1

        if duplicates_removed > 0:
            logger.warning(
                f"üîç –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è Ozon: {total_records} –∑–∞–ø–∏—Å–µ–π ‚Üí "
                f"{len(unique_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö (—É–¥–∞–ª–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, "
                f"{duplicates_removed/total_records*100:.1f}%)"
            )
        else:
            logger.info(f"‚úÖ Ozon: {len(unique_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        return unique_data


class ChunkedAPIManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è chunked API –∑–∞–ø—Ä–æ—Å–∞–º–∏"""

    def __init__(self, api_clients):
        self.api_clients = api_clients
        self.chunker = APIChunker()

    async def get_wb_sales_chunked(self, date_from: str, date_to: str) -> list[dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ WB Sales –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —á–∞–Ω–∫–∞–º"""

        async def get_wb_sales_for_period(chunk_from: str, chunk_to: str) -> list[dict]:
            """–ü–æ–ª—É—á–µ–Ω–∏–µ WB –ø—Ä–æ–¥–∞–∂ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
            sales_url = f"{self.api_clients.wb_api.STATS_BASE_URL}/api/v1/supplier/sales"
            sales_params = {"dateFrom": chunk_from, "dateTo": chunk_to, "limit": 100000}
            sales_headers = self.api_clients.wb_api._get_headers("stats")

            return (
                await self.api_clients.wb_api._make_request_with_retry(
                    "GET", sales_url, sales_headers, params=sales_params
                )
                or []
            )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–µ—Ä–∏–æ–¥–∞
        from datetime import datetime

        start_date = datetime.strptime(date_from, "%Y-%m-%d")
        end_date = datetime.strptime(date_to, "%Y-%m-%d")
        period_days = (end_date - start_date).days

        if period_days > 300:  # –ì–æ–¥ –∏ –±–æ–ª–µ–µ - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
            delay = 8.0  # –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –ë–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –≥–æ–¥–æ–≤—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
            logger.info(f"–ì–æ–¥–æ–≤–æ–π –ø–µ—Ä–∏–æ–¥ ({period_days} –¥–Ω–µ–π) - –∑–∞–¥–µ—Ä–∂–∫–∞ {delay}s –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏")
        elif period_days > 180:  # –ë–æ–ª–µ–µ –ø–æ–ª—É–≥–æ–¥–∞
            delay = 5.0  # –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            logger.info(
                f"–û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –ø–µ—Ä–∏–æ–¥ ({period_days} –¥–Ω–µ–π) - –∑–∞–¥–µ—Ä–∂–∫–∞ {delay}s –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏"
            )
        elif period_days > 90:  # –ë–æ–ª–µ–µ 3 –º–µ—Å—è—Ü–µ–≤
            delay = 3.5  # –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            logger.info(f"–ë–æ–ª—å—à–æ–π –ø–µ—Ä–∏–æ–¥ ({period_days} –¥–Ω–µ–π) - –∑–∞–¥–µ—Ä–∂–∫–∞ {delay}s –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏")
        elif period_days > 30:  # –ë–æ–ª–µ–µ –º–µ—Å—è—Ü–∞
            delay = 2.5  # –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
            logger.info(f"–°—Ä–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ ({period_days} –¥–Ω–µ–π) - –∑–∞–¥–µ—Ä–∂–∫–∞ {delay}s –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏")
        else:
            delay = 2.0  # –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            logger.info(f"–ö–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥ ({period_days} –¥–Ω–µ–π) - –∑–∞–¥–µ—Ä–∂–∫–∞ {delay}s –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏")

        results = await self.chunker.process_chunked_request(
            get_wb_sales_for_period, date_from, date_to, "wb_sales", delay_between_requests=delay
        )
        return self.chunker.aggregate_wb_sales_data(results)

    async def get_wb_orders_chunked(self, date_from: str, date_to: str) -> list[dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ WB Orders –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —á–∞–Ω–∫–∞–º"""

        async def get_wb_orders_for_period(chunk_from: str, chunk_to: str) -> list[dict]:
            """–ü–æ–ª—É—á–µ–Ω–∏–µ WB –∑–∞–∫–∞–∑–æ–≤ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
            orders_url = f"{self.api_clients.wb_api.STATS_BASE_URL}/api/v1/supplier/orders"
            orders_params = {"dateFrom": chunk_from, "dateTo": chunk_to, "limit": 100000}
            orders_headers = self.api_clients.wb_api._get_headers("stats")

            return (
                await self.api_clients.wb_api._make_request_with_retry(
                    "GET", orders_url, orders_headers, params=orders_params
                )
                or []
            )

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∞–∫—É—é –∂–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –∫–∞–∫ –¥–ª—è Sales
        from datetime import datetime

        start_date = datetime.strptime(date_from, "%Y-%m-%d")
        end_date = datetime.strptime(date_to, "%Y-%m-%d")
        period_days = (end_date - start_date).days

        if period_days > 300:
            delay = 8.0
        elif period_days > 180:
            delay = 5.0
        elif period_days > 90:
            delay = 3.5
        elif period_days > 30:
            delay = 2.5
        else:
            delay = 2.0

        results = await self.chunker.process_chunked_request(
            get_wb_orders_for_period,
            date_from,
            date_to,
            "wb_orders",
            delay_between_requests=delay,  # –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        )
        return self.chunker.aggregate_wb_orders_data(results)

    async def get_wb_advertising_chunked(self, date_from: str, date_to: str) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ WB Advertising –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —á–∞–Ω–∫–∞–º"""
        results = await self.chunker.process_chunked_request(
            self.api_clients.wb_business_api.get_advertising_statistics,
            date_from,
            date_to,
            "wb_advertising",
            delay_between_requests=3.0,  # –ë–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è Adv API
        )
        return self.chunker.aggregate_wb_advertising_data(results)

    async def get_ozon_fbo_chunked(self, date_from: str, date_to: str) -> list[dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ Ozon FBO –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —á–∞–Ω–∫–∞–º"""
        from datetime import datetime

        from api_clients.ozon.sales_client import OzonSalesClient

        async def get_ozon_fbo_for_period(chunk_from: str, chunk_to: str) -> list[dict]:
            """–ü–æ–ª—É—á–µ–Ω–∏–µ Ozon FBO –∑–∞–∫–∞–∑–æ–≤ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
            logger.info(f"–ü–æ–ª—É—á–∞–µ–º Ozon FBO –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–µ—Ä–∏–æ–¥ {chunk_from} - {chunk_to}")
            sales_client = OzonSalesClient()
            date_from_obj = datetime.strptime(chunk_from, "%Y-%m-%d").date()
            date_to_obj = datetime.strptime(chunk_to, "%Y-%m-%d").date()

            try:
                fbo_data = await sales_client.get_fbo_orders(date_from_obj, date_to_obj)
                logger.info(
                    f"Ozon FBO: –ø–æ–ª—É—á–µ–Ω–æ {len(fbo_data) if fbo_data else 0} –∑–∞–ø–∏—Å–µ–π –∑–∞ {chunk_from} - {chunk_to}"
                )

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞
                if isinstance(fbo_data, dict):
                    result = fbo_data.get("result", {})
                    if isinstance(result, dict):
                        return result.get("postings", [])
                    elif isinstance(result, list):
                        return result
                    else:
                        return []
                elif isinstance(fbo_data, list):
                    return fbo_data
                else:
                    return []

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è Ozon FBO –¥–ª—è {chunk_from}-{chunk_to}: {e}")
                return []

        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è Ozon FBO
        start_date = datetime.strptime(date_from, "%Y-%m-%d")
        end_date = datetime.strptime(date_to, "%Y-%m-%d")
        period_days = (end_date - start_date).days

        if period_days > 300:
            delay = 4.0  # –ì–æ–¥
        elif period_days > 180:
            delay = 3.0  # –ü–æ–ª—É–≥–æ–¥–∏–µ
        elif period_days > 90:
            delay = 2.5  # –ö–≤–∞—Ä—Ç–∞–ª
        else:
            delay = 2.0  # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–µ—Ä–∏–æ–¥—ã

        results = await self.chunker.process_chunked_request(
            get_ozon_fbo_for_period, date_from, date_to, "ozon_fbo", delay_between_requests=delay
        )
        return self.chunker.aggregate_ozon_data(results)

    async def get_ozon_fbs_chunked(self, date_from: str, date_to: str) -> list[dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ Ozon FBS –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —á–∞–Ω–∫–∞–º"""
        from datetime import datetime

        from api_clients.ozon.sales_client import OzonSalesClient

        async def get_ozon_transactions_for_period(chunk_from: str, chunk_to: str) -> list[dict]:
            """–ü–æ–ª—É—á–µ–Ω–∏–µ Ozon —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
            logger.info(f"–ü–æ–ª—É—á–∞–µ–º Ozon FBS —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ {chunk_from} - {chunk_to}")
            sales_client = OzonSalesClient()
            date_from_obj = datetime.strptime(chunk_from, "%Y-%m-%d").date()
            date_to_obj = datetime.strptime(chunk_to, "%Y-%m-%d").date()

            transactions = await sales_client.get_transactions(date_from_obj, date_to_obj)
            logger.info(
                f"Ozon FBS: –ø–æ–ª—É—á–µ–Ω–æ {len(transactions) if transactions else 0} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∑–∞ {chunk_from} - {chunk_to}"
            )
            return transactions if transactions else []

        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è Ozon FBS
        start_date = datetime.strptime(date_from, "%Y-%m-%d")
        end_date = datetime.strptime(date_to, "%Y-%m-%d")
        period_days = (end_date - start_date).days

        if period_days > 300:
            delay = 4.0  # –ì–æ–¥
        elif period_days > 180:
            delay = 3.0  # –ü–æ–ª—É–≥–æ–¥–∏–µ
        elif period_days > 90:
            delay = 2.5  # –ö–≤–∞—Ä—Ç–∞–ª
        else:
            delay = 2.0  # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–µ—Ä–∏–æ–¥—ã

        results = await self.chunker.process_chunked_request(
            get_ozon_transactions_for_period,
            date_from,
            date_to,
            "ozon_fbs",
            delay_between_requests=delay,
        )
        return self.chunker.aggregate_ozon_data(results)
